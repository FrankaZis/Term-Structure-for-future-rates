{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Constant_Maturity_ED.csv',index_col = 'Date')\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ED1</th>\n",
       "      <th>ED2</th>\n",
       "      <th>ED3</th>\n",
       "      <th>ED4</th>\n",
       "      <th>ED5</th>\n",
       "      <th>ED6</th>\n",
       "      <th>ED7</th>\n",
       "      <th>ED8</th>\n",
       "      <th>ED9</th>\n",
       "      <th>ED10</th>\n",
       "      <th>ED11</th>\n",
       "      <th>ED12</th>\n",
       "      <th>ED13</th>\n",
       "      <th>ED14</th>\n",
       "      <th>ED15</th>\n",
       "      <th>ED16</th>\n",
       "      <th>ED17</th>\n",
       "      <th>ED18</th>\n",
       "      <th>ED19</th>\n",
       "      <th>ED20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>6.300146</td>\n",
       "      <td>6.579726</td>\n",
       "      <td>6.805882</td>\n",
       "      <td>7.018287</td>\n",
       "      <td>7.028155</td>\n",
       "      <td>7.119748</td>\n",
       "      <td>7.163734</td>\n",
       "      <td>7.230232</td>\n",
       "      <td>7.184041</td>\n",
       "      <td>7.195232</td>\n",
       "      <td>7.205515</td>\n",
       "      <td>7.265000</td>\n",
       "      <td>7.235150</td>\n",
       "      <td>7.259495</td>\n",
       "      <td>7.278118</td>\n",
       "      <td>7.358092</td>\n",
       "      <td>7.354708</td>\n",
       "      <td>7.396914</td>\n",
       "      <td>7.427265</td>\n",
       "      <td>7.506268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>6.275171</td>\n",
       "      <td>6.532367</td>\n",
       "      <td>6.763403</td>\n",
       "      <td>6.963487</td>\n",
       "      <td>6.973894</td>\n",
       "      <td>7.065366</td>\n",
       "      <td>7.109766</td>\n",
       "      <td>7.180379</td>\n",
       "      <td>7.133714</td>\n",
       "      <td>7.145372</td>\n",
       "      <td>7.155975</td>\n",
       "      <td>7.210109</td>\n",
       "      <td>7.180000</td>\n",
       "      <td>7.204755</td>\n",
       "      <td>7.223725</td>\n",
       "      <td>7.303605</td>\n",
       "      <td>7.299734</td>\n",
       "      <td>7.342448</td>\n",
       "      <td>7.372636</td>\n",
       "      <td>7.452906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>6.294548</td>\n",
       "      <td>6.582542</td>\n",
       "      <td>6.820957</td>\n",
       "      <td>7.014204</td>\n",
       "      <td>7.030129</td>\n",
       "      <td>7.126494</td>\n",
       "      <td>7.175916</td>\n",
       "      <td>7.250987</td>\n",
       "      <td>7.213686</td>\n",
       "      <td>7.225527</td>\n",
       "      <td>7.241706</td>\n",
       "      <td>7.300245</td>\n",
       "      <td>7.269865</td>\n",
       "      <td>7.295000</td>\n",
       "      <td>7.319284</td>\n",
       "      <td>7.404037</td>\n",
       "      <td>7.399817</td>\n",
       "      <td>7.442871</td>\n",
       "      <td>7.477671</td>\n",
       "      <td>7.564385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>6.292558</td>\n",
       "      <td>6.563636</td>\n",
       "      <td>6.792313</td>\n",
       "      <td>6.974441</td>\n",
       "      <td>6.990855</td>\n",
       "      <td>7.087533</td>\n",
       "      <td>7.142152</td>\n",
       "      <td>7.215723</td>\n",
       "      <td>7.173301</td>\n",
       "      <td>7.185680</td>\n",
       "      <td>7.202299</td>\n",
       "      <td>7.260325</td>\n",
       "      <td>7.229766</td>\n",
       "      <td>7.255227</td>\n",
       "      <td>7.275000</td>\n",
       "      <td>7.359521</td>\n",
       "      <td>7.354867</td>\n",
       "      <td>7.398412</td>\n",
       "      <td>7.433124</td>\n",
       "      <td>7.521096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>6.276060</td>\n",
       "      <td>6.525951</td>\n",
       "      <td>6.753566</td>\n",
       "      <td>6.918970</td>\n",
       "      <td>6.937110</td>\n",
       "      <td>7.032297</td>\n",
       "      <td>7.077964</td>\n",
       "      <td>7.156076</td>\n",
       "      <td>7.112993</td>\n",
       "      <td>7.125816</td>\n",
       "      <td>7.142907</td>\n",
       "      <td>7.200386</td>\n",
       "      <td>7.169677</td>\n",
       "      <td>7.195443</td>\n",
       "      <td>7.215701</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>7.294925</td>\n",
       "      <td>7.338949</td>\n",
       "      <td>7.373583</td>\n",
       "      <td>7.462833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ED1       ED2       ED3       ED4       ED5       ED6  \\\n",
       "Date                                                                     \n",
       "2000-01-03  6.300146  6.579726  6.805882  7.018287  7.028155  7.119748   \n",
       "2000-01-04  6.275171  6.532367  6.763403  6.963487  6.973894  7.065366   \n",
       "2000-01-05  6.294548  6.582542  6.820957  7.014204  7.030129  7.126494   \n",
       "2000-01-06  6.292558  6.563636  6.792313  6.974441  6.990855  7.087533   \n",
       "2000-01-07  6.276060  6.525951  6.753566  6.918970  6.937110  7.032297   \n",
       "\n",
       "                 ED7       ED8       ED9      ED10      ED11      ED12  \\\n",
       "Date                                                                     \n",
       "2000-01-03  7.163734  7.230232  7.184041  7.195232  7.205515  7.265000   \n",
       "2000-01-04  7.109766  7.180379  7.133714  7.145372  7.155975  7.210109   \n",
       "2000-01-05  7.175916  7.250987  7.213686  7.225527  7.241706  7.300245   \n",
       "2000-01-06  7.142152  7.215723  7.173301  7.185680  7.202299  7.260325   \n",
       "2000-01-07  7.077964  7.156076  7.112993  7.125816  7.142907  7.200386   \n",
       "\n",
       "                ED13      ED14      ED15      ED16      ED17      ED18  \\\n",
       "Date                                                                     \n",
       "2000-01-03  7.235150  7.259495  7.278118  7.358092  7.354708  7.396914   \n",
       "2000-01-04  7.180000  7.204755  7.223725  7.303605  7.299734  7.342448   \n",
       "2000-01-05  7.269865  7.295000  7.319284  7.404037  7.399817  7.442871   \n",
       "2000-01-06  7.229766  7.255227  7.275000  7.359521  7.354867  7.398412   \n",
       "2000-01-07  7.169677  7.195443  7.215701  7.300000  7.294925  7.338949   \n",
       "\n",
       "                ED19      ED20  \n",
       "Date                            \n",
       "2000-01-03  7.427265  7.506268  \n",
       "2000-01-04  7.372636  7.452906  \n",
       "2000-01-05  7.477671  7.564385  \n",
       "2000-01-06  7.433124  7.521096  \n",
       "2000-01-07  7.373583  7.462833  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Sample\n",
    "SampleA = df['2011-01-01':'2015-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def CCA_Chou_Ng(data_set):\n",
    "    \n",
    "    #data_set is pandas dataframe\n",
    "    df_lag = data_set.shift(1).dropna()\n",
    "    df = data_set.drop(data_set.index[0]).dropna()\n",
    "    n = len(data_set.columns)\n",
    "    \n",
    "    #X(t) ~ M_1 + X(t-1)\n",
    "    X = df_lag.as_matrix()\n",
    "    X_I = sm.add_constant(X) #assure there is a constant term\n",
    "    Y = df.as_matrix()\n",
    "    l1 = sm.OLS(Y,X_I).fit()\n",
    "    B=l1.params[1:(n+1)]\n",
    "    \n",
    "    #X(t-1) ~ M_2 + X(t)\n",
    "    Y_I = sm.add_constant(X)\n",
    "    l2 = sm.OLS(X,Y_I).fit()\n",
    "    A=l2.params[1:(n+1)]\n",
    "    C = np.dot(A,B)\n",
    "    eig_val, eig_vec = np.linalg.eig(C)\n",
    "    return eig_val, eig_vec, C # Notice each column rather than row in eig_vec is an eigenvector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.86614623,  0.49979066]), array([-0.79869269,  0.60173914]), array([-0.70990087,  0.70430161]), array([-0.93135808,  0.36410455]), array([-0.72668716,  0.68696854])]\n"
     ]
    }
   ],
   "source": [
    "# 5 Pairs \n",
    "Pairslist = [['ED8','ED12'],['ED12','ED16'],['ED16','ED20'],['ED8','ED16'],['ED12','ED20']]\n",
    "\n",
    "# weights list corresponding to pairs\n",
    "wlist = []\n",
    "for pair in Pairslist:\n",
    "    val, vec, C = CCA_Chou_Ng(SampleA[pair])\n",
    "    w = vec[:,val.argmin()]\n",
    "    wlist.append(w)\n",
    "print(wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal 1: \n",
      "            beta0     beta1  half_life\n",
      "(2y,3y) -0.057478  0.981400  36.917515\n",
      "(3y,4y)  0.036673  0.985892  48.785330\n",
      "(4y,5y)  0.393135  0.721335   2.121981\n",
      "(2y,4y) -0.144839  0.984056  43.127318\n",
      "(3y,5y)  0.804406  0.929740   9.514734\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima_model import ARMA\n",
    "\n",
    "# Construct Signal 1\n",
    "# Parameters list\n",
    "paralist1 = []\n",
    "\n",
    "for i in range(len(wlist)):\n",
    "    \n",
    "    # Signal 1 cointegrated vector\n",
    "    citg_vec = SampleA[Pairslist[i]].dot(wlist[i])\n",
    "    \n",
    "    # AR(1) Model fit\n",
    "    model = ARMA(citg_vec,(1,0)).fit(ic = 'aic',trend = 'c')\n",
    "    params = model.params.values\n",
    "    \n",
    "    # Calculate half-life\n",
    "    half_life = -np.log(2)/np.log(params[1])\n",
    "    \n",
    "    # Append parameters\n",
    "    paralist1.append(np.append(params,half_life))\n",
    "\n",
    "# Print out AR(1) fitting results and halflife\n",
    "print('Signal 1: ')\n",
    "pp = ['(2y,3y)','(3y,4y)','(4y,5y)','(2y,4y)','(3y,5y)']\n",
    "print(pd.DataFrame(paralist1,index=pp,columns=['beta0','beta1','half_life']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EWMA series whcih admit lambda>1\n",
    "def EWMA(series,lambda_):\n",
    "    ewma = series[0]\n",
    "    ewmalist = [ewma]\n",
    "    for i in range(1,len(series)):\n",
    "        ewma = ewma*lambda_+series[i]*(1-lambda_)\n",
    "        ewmalist.append(ewma)\n",
    "    return np.array(ewmalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given lambda, return the distance of halflife and 5\n",
    "def lambdaerror(lambda_):\n",
    "    citg_ewm = citg_vec - EWMA(citg_vec,lambda_)\n",
    "    model = ARMA(citg_ewm,(1,0)).fit(ic = 'aic',trend = 'c')\n",
    "    params = model.params\n",
    "    half_life = -np.log(2)/np.log(abs(params[1]))\n",
    "    return abs(5-half_life)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xj537\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal 2: \n",
      "            beta0     beta1  half_life    lambda\n",
      "(2y,3y) -0.005175  0.870547   4.999872  0.954802\n",
      "(3y,4y) -0.004915  0.870553   5.000112  0.951541\n",
      "(4y,5y)  0.167007  0.870547   4.999852  1.004874\n",
      "(2y,4y) -0.007958  0.870557   5.000249  0.953184\n",
      "(3y,5y) -0.048562  0.870548   4.999893  0.991520\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "# Construct Signal 2\n",
    "# Parameters list\n",
    "paralist2 = []\n",
    "\n",
    "for i in range(len(wlist)):\n",
    "    \n",
    "    # Signal 1 cointegrated vector\n",
    "    citg_vec = (SampleA[Pairslist[i]].values).dot(wlist[i])\n",
    "    \n",
    "    # Find lambda which assures halflife of signal2 is 5\n",
    "    minimizer = minimize(lambdaerror,x0=0.94,method='Nelder-Mead')\n",
    "    lambda_ =  minimizer['x']\n",
    "    \n",
    "    # Signal 2 cointegrated vector = Signal1 - EWMA \n",
    "    citg_vec = citg_vec - EWMA(citg_vec,lambda_)\n",
    "    \n",
    "    # AR(1) Model fit\n",
    "    model = ARMA(citg_vec,(1,0)).fit(ic = 'aic',trend = 'c')\n",
    "    params = model.params\n",
    "    \n",
    "    # Calculate halflife which should be 5\n",
    "    half_life = -np.log(2)/np.log(params[1])\n",
    "     \n",
    "    # Append parameters\n",
    "    paralist2.append(np.append(np.append(params,half_life),lambda_))\n",
    "\n",
    "# Print out AR(1) fitting results, lambda and halflife\n",
    "print('Signal 2: ')\n",
    "pp = ['(2y,3y)','(3y,4y)','(4y,5y)','(2y,4y)','(3y,5y)']\n",
    "print(pd.DataFrame(paralist2,index=pp,columns=['beta0','beta1','half_life','lambda']))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Sample\n",
    "SampleB = df['2015-01-01':'2016-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AR1forecast(current, beta0, beta1, H):\n",
    "    # current can be a vector\n",
    "    forecast = current\n",
    "    for i in range(H):\n",
    "        forecast = forecast*beta1 + beta0\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def metric(signal, forecast):\n",
    "    \n",
    "    # Remove useless data in start and end. Remove data where difference is less than 0.1\n",
    "    signal_slice = signal[10:]\n",
    "    forecast_slice = forecast[:-10]\n",
    "    signal_comp = signal_slice[abs(signal_slice-forecast_slice)>0.1]\n",
    "    forecast_comp = forecast_slice[abs(signal_slice-forecast_slice)>0.1]    \n",
    "    \n",
    "    # calculate residuals\n",
    "    residuals = signal_comp - forecast_comp\n",
    "    \n",
    "    # calculate pearson correlation\n",
    "    corr = pearsonr(signal_comp,forecast_comp)[0]\n",
    "    \n",
    "    # calculate root mean squared error\n",
    "    rmse = np.sqrt((residuals*2).mean())\n",
    "    \n",
    "    return corr, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QualityAnalysis(w, Sample):\n",
    "\n",
    "    corrlist = []\n",
    "    rmselist = []\n",
    "    \n",
    "    for i in range(len(Pairslist)):\n",
    "\n",
    "        # Biuld Signal1, Signal2 and Signal3. Signal3 is gaussian mixture of Signal1&2 with weights theta(w,1-w).\n",
    "        signal1 = (Sample[Pairslist[i]].values).dot(wlist[i])\n",
    "        signal2 = signal1 - EWMA(signal1,paralist2[i][3])\n",
    "        signal3 = w*signal1 + (1-w) *signal2     \n",
    "\n",
    "        # Forecast horizon H, which means forecasting H days after\n",
    "        H = 10\n",
    "\n",
    "        # Forecast of signal1 where horizon is H\n",
    "        forecast1 = AR1forecast(signal1, paralist1[i][0], paralist1[i][1], H)\n",
    "\n",
    "        # Forecast of signal2 where horizon is H\n",
    "        forecast2 = AR1forecast(signal2, paralist2[i][0], paralist2[i][1], H)\n",
    "\n",
    "        # Forecast of signal3 where horizon is H and weights is (w,1-w)\n",
    "        forecast3 = w*forecast1 + (1-w)*forecast2\n",
    "\n",
    "        # calculate metrics\n",
    "        corr1, ms1 = metric(signal1, forecast1)\n",
    "        corr2, ms2 = metric(signal2, forecast2)\n",
    "        corr3, ms3 = metric(signal3, forecast3)\n",
    "        corrlist.append([corr1, corr2, corr3])\n",
    "        rmselist.append([ms1, ms2, ms3])\n",
    "\n",
    "    # calculate mean of all cointegrated pairs\n",
    "    ave_corr = pd.DataFrame(corrlist).mean().values\n",
    "    ave_rmse = pd.DataFrame(rmselist).mean().values\n",
    "    \n",
    "    metrics = pd.DataFrame(np.array([ave_corr,ave_rmse]).T, index=['signal1','signal2','signal3'],columns=['CORR','RMSE'])\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORR</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>signal1</th>\n",
       "      <td>0.706694</td>\n",
       "      <td>1.272676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signal2</th>\n",
       "      <td>0.684891</td>\n",
       "      <td>0.551710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signal3</th>\n",
       "      <td>0.604775</td>\n",
       "      <td>0.920395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CORR      RMSE\n",
       "signal1  0.706694  1.272676\n",
       "signal2  0.684891  0.551710\n",
       "signal3  0.604775  0.920395"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QualityAnalysis(0.5, SampleB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toOptimizew(w, Sample):\n",
    "    \n",
    "    # Rescale metrics\n",
    "    metrics = QualityAnalysis(w, Sample)\n",
    "    corr_rescale = metrics.iloc[:,1]/metrics.iloc[:,1].mean()\n",
    "    RMSE_rescale = metrics.iloc[:,0]/metrics.iloc[:,0].mean()\n",
    "    \n",
    "    # Combine two metrics to optimize signal3 weight. The smaller combined metirc, the better model is.\n",
    "    CombMetric = sum(abs(RMSE_rescale/corr_rescale))\n",
    "    #CombMetric = sum(abs(metrics.iloc[:,1]/metrics.iloc[:,0]))\n",
    "    \n",
    "    return CombMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal W:  [0.35543532]\n"
     ]
    }
   ],
   "source": [
    "minimizer = minimize(toOptimizew,0.6,args=(SampleB),bounds=[(0,1)])\n",
    "Optimalw = minimizer['x']\n",
    "print('Optimal W: ', Optimalw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Sample\n",
    "SampleC = df['2016-01-01':'2017-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devide into four quarters\n",
    "SampleC1 = SampleC['2016-01-01':'2016-04-01']\n",
    "SampleC2 = SampleC['2016-04-01':'2016-07-01']\n",
    "SampleC3 = SampleC['2016-07-01':'2016-10-01']\n",
    "SampleC4 = SampleC['2016-10-01':'2017-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1:\n",
      "             CORR      RMSE\n",
      "signal1  0.215136  1.303990\n",
      "signal2  0.345577  0.595858\n",
      "signal3  0.205381  0.849959\n",
      "Combined Metric:  3.541233653231919\n",
      "\n",
      "\n",
      "Q2:\n",
      "             CORR      RMSE\n",
      "signal1  0.111295  1.287085\n",
      "signal2  0.514837  0.563672\n",
      "signal3  0.140456  0.799511\n",
      "Combined Metric:  4.064009434578916\n",
      "\n",
      "\n",
      "Q3:\n",
      "             CORR      RMSE\n",
      "signal1  0.213459  1.267783\n",
      "signal2 -0.066878  0.680515\n",
      "signal3 -0.200113  0.761108\n",
      "Combined Metric:  26.80296196096009\n",
      "\n",
      "\n",
      "Q4:\n",
      "             CORR      RMSE\n",
      "signal1  0.534266  1.223124\n",
      "signal2  0.332559  0.777767\n",
      "signal3  0.454130  0.723741\n",
      "Combined Metric:  3.0771485495619926\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quality analysis on test sample\n",
    "print('Q1:')\n",
    "print(QualityAnalysis(Optimalw, SampleC1))\n",
    "print('Combined Metric: ', toOptimizew(Optimalw, SampleC1))\n",
    "print('\\n')\n",
    "\n",
    "print('Q2:')\n",
    "print(QualityAnalysis(Optimalw, SampleC2))\n",
    "print('Combined Metric: ', toOptimizew(Optimalw, SampleC2))\n",
    "print('\\n')\n",
    "\n",
    "print('Q3:')\n",
    "print(QualityAnalysis(Optimalw, SampleC3))\n",
    "print('Combined Metric: ', toOptimizew(Optimalw, SampleC3))\n",
    "print('\\n')\n",
    "\n",
    "print('Q4:')\n",
    "print(QualityAnalysis(Optimalw, SampleC4))\n",
    "print('Combined Metric: ', toOptimizew(Optimalw, SampleC4))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "    We should expect that as time passes, our signal forecast quality should decrease. But in my results, we can see quality increases in the first 3 season. It may reflect our model is not that robust. But we can see quality does decrease in the 4th quarter, it may imply our model is fine. The first 3 season may be some accidently things that our model doesn't learn. Maybe our model will be more robust if we use more traing datas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2F Short Rate Model:\n",
    "# r(t) = x1(t) + x2(t)\n",
    "# dxi(t) = (ui - kixi(t))dt + sigmai dWit,  i = 1,2\n",
    "# dW1t dW2t = rou dt\n",
    "\n",
    "class Model:\n",
    "    def __init__(self,x1,x2,mu1,mu2,k1,k2,sigma1,sigma2,rou):\n",
    "        self.mu1 =mu1\n",
    "        self.mu2 = mu2\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.sigma1 = sigma1\n",
    "        self.sigma2 = sigma2\n",
    "        self.rou = rou\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        \n",
    "    # Conditional mean of X1(t) given X1(0)=x1   \n",
    "    def mean_x1(self,t): \n",
    "        m = self.x1*np.exp(-self.k1*t) + self.mu1/self.k1*(1-np.exp(-self.k1*t))\n",
    "        return m\n",
    "    \n",
    "    # Conditional mean of X2(t) given X2(0)=x1\n",
    "    def mean_x2(self,t):\n",
    "        m = self.x2*np.exp(-self.k2*t) + self.mu2/self.k2*(1-np.exp(-self.k2*t))\n",
    "        return m\n",
    "    \n",
    "    # Conditional var of X1(t) given X1(0)=x1\n",
    "    def var_x1(self,t):\n",
    "        v = self.sigma1**2/2/self.k1*(1-np.exp(-2*self.k1*t))\n",
    "        return v\n",
    "    \n",
    "    # Conditional var of X2(t) given X2(0)=x1\n",
    "    def var_x2(self,t):\n",
    "        v = self.sigma2**2/2/self.k2*(1-np.exp(-2*self.k2*t))\n",
    "        return v\n",
    "    \n",
    "    def A(self,tau):\n",
    "        c1 = self.mu1/self.k1+self.mu2/self.k2-self.sigma1**2/2/self.k1**2-self.sigma2**2/2/self.k2**2-self.sigma1*self.sigma2*self.rou/self.k1/self.k2\n",
    "        c2 = self.sigma1**2/self.k1**3+self.sigma1*self.sigma2*self.rou/2/self.k1**2/self.k2-self.mu1/self.k1**2\n",
    "        c3 = self.sigma2**2/self.k2**3+self.sigma1*self.sigma2*self.rou/2/self.k2**2/self.k1-self.mu2/self.k2**2\n",
    "        c4 = self.sigma1**2/4/self.k1**3\n",
    "        c5 = self.sigma2**2/4/self.k2**3\n",
    "        c6 = self.sigma1*self.sigma2*self.rou/self.k1/self.k2/(self.k1+self.k2)\n",
    "        a1 = c1*tau+c2*(1-np.exp(-self.k1*tau))+c3*(1-np.exp(-self.k2*tau))\n",
    "        a2 = c4*(1-np.exp(-2*self.k1*tau)) + c5*(1-np.exp(-2*self.k2*tau)) +c6*(1-np.exp(-(self.k1+self.k2)*tau))\n",
    "        a = a1 - a2\n",
    "        return a\n",
    "\n",
    "    def B1(self,tau):\n",
    "        b1 = (1-np.exp(-self.k1*tau))/self.k1\n",
    "        return b1\n",
    "    \n",
    "    def B2(self,tau):\n",
    "        b2 = (1-np.exp(-self.k2*tau))/self.k2\n",
    "        return b2\n",
    "    \n",
    "    # forward rate if forward rate fix time is t_fix, forward rate start time is T0 and forward rate end time is T1\n",
    "    def fwd_rate(self,t_fix,T0,T1):\n",
    "        A_diff = self.A(T0-t_fix) - self.A(T1-t_fix)\n",
    "        B1_diff = self.B1(T0-t_fix) - self.B1(T1-t_fix)\n",
    "        B2_diff = self.B2(T0-t_fix) - self.B2(T1-t_fix)\n",
    "        b1 = - B1_diff*self.mean_x1(t_fix) + (B1_diff**2)*self.var_x1(t_fix)/2\n",
    "        b2 = - B2_diff*self.mean_x2(t_fix) + (B2_diff**2)*self.var_x2(t_fix)/2\n",
    "        bcross = B1_diff*B2_diff*self.rou*np.sqrt(self.var_x1(t_fix)*self.var_x2(t_fix))\n",
    "        f = (np.exp(-A_diff + b1 + b2 + bcross) - 1)/(T1-T0)\n",
    "        return f\n",
    "    \n",
    "    # Update latent variable\n",
    "    def update_x(self,x):\n",
    "        self.x1 = x[0]\n",
    "        self.x2 = x[1]\n",
    "        \n",
    "    # Update measure relavent variable\n",
    "    def update_p(self,p):\n",
    "        self.mu1 = p[0]\n",
    "        self.mu2 = p[1]\n",
    "        self.k1 = p[2]\n",
    "        self.k2 = p[3]\n",
    "    \n",
    "    # Update measure irrelavent variable\n",
    "    def update_c(self,c):\n",
    "        self.sigma1 = c[0]\n",
    "        self.sigma2 = c[1]\n",
    "        self.rou = c[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import least_squares, leastsq\n",
    "class xFitter:\n",
    "    \n",
    "    # This class is a inner loop to fit latent variable x to real data fut_data if other parameters are given\n",
    "    def __init__(self,model,fut_data,terms):\n",
    "        self.model = model\n",
    "        self.data = np.array(fut_data)\n",
    "        self.terms = terms\n",
    "    \n",
    "    # residuals of fitting\n",
    "    def residuals(self,x):\n",
    "        m = self.model\n",
    "        m.update_x(x)\n",
    "        rate_dist = [m.fwd_rate(t,t,t+0.25)*100 for t in self.terms]\n",
    "        return np.array(rate_dist) - self.data\n",
    "    \n",
    "    # perform fitting using least square method\n",
    "    def fit(self,x0,solver='lm'):\n",
    "        return least_squares(self.residuals,x0,method=solver,xtol = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pFitter:\n",
    "    \n",
    "    # This class is a outer loop to fit p to real data fut_data while fiting x is inner loop and c is updated by x \n",
    "    def __init__(self,model,sample,terms):\n",
    "        self.model = model\n",
    "        self.sample = sample\n",
    "        self.terms = terms\n",
    "    \n",
    "    # Fit x for all days and return x series and residuals dataframe\n",
    "    def Fitallx(self,p):\n",
    "        \n",
    "        m = self.model\n",
    "        m.update_p(p)\n",
    "        \n",
    "        # Store optimal x for each day into a list\n",
    "        xlist=[]\n",
    "\n",
    "        # Store residuals for each day and each futurerate into a list\n",
    "        residuallist = []\n",
    "        \n",
    "        for ix in self.sample.index:\n",
    "            \n",
    "            # fit x for each day\n",
    "            xfitter = xFitter(m,self.sample.loc[ix],self.terms)\n",
    "            optimalx = xfitter.fit([0.02,0.02])['x']\n",
    "            xlist.append(optimalx)\n",
    "            residuallist.append(xfitter.residuals(optimalx))\n",
    "        \n",
    "        xseries = pd.DataFrame(xlist,index=self.sample.index,columns=['x1','x2'])\n",
    "        residuals = pd.DataFrame(residuallist,index=self.sample.index,columns=self.sample.columns)\n",
    "        return xseries,residuals\n",
    "    \n",
    "    # Calculate Jacobian Matrix\n",
    "    def Jacobian(self,p,initial):\n",
    "        \n",
    "        Jacobian = []\n",
    "        for i in range(len(p)):\n",
    "            \n",
    "            # For each parameter, calculate derivative\n",
    "            p[i] = p[i] + 0.000001\n",
    "            SSE = ((self.Fitallx(p)[1])**2).mean().mean()\n",
    "            J = (SSE - initial)/0.000001\n",
    "            Jacobian.append(J)\n",
    "            p[i] = p[i] - 0.000001\n",
    "        \n",
    "        return np.array(Jacobian)\n",
    "        \n",
    "    # perform fit\n",
    "    def fit(self, p0, solver='lm'):\n",
    "        \n",
    "        p = p0\n",
    "        SSE = 0\n",
    "        preSSE = 1000\n",
    "        \n",
    "        # Control terminal\n",
    "        while abs(SSE-preSSE)>0.01:\n",
    "            \n",
    "            # See parameters in each loop\n",
    "            preSSE = SSE\n",
    "            #print(SSE)\n",
    "            #print('p: ',p)\n",
    "            #print('c: ',[self.model.sigma1,self.model.sigma2,self.model.rou])\n",
    "            \n",
    "            # fit x assume p and c given\n",
    "            xseries, residuals = self.Fitallx(p)\n",
    "            \n",
    "            # Calculate sum squared error\n",
    "            SSE = (residuals**2).mean().mean()\n",
    "            \n",
    "            # Calculate Jacobian and Hessian\n",
    "            Jac = self.Jacobian(p,SSE)\n",
    "            Hess = Jac.reshape(-1,1).dot(Jac.reshape(1,-1))\n",
    "           \n",
    "            # Detect collinearity, if condition number is greater than 1000\n",
    "            eig = np.linalg.eig(Hess)[0]\n",
    "            condnum = abs(eig.max()/eig.min())\n",
    "            \n",
    "            # Use ridge method to handle collinearity \n",
    "            if condnum>1000:\n",
    "                Hess = Hess  + 0.00001*np.eye(len(Jac))\n",
    "            \n",
    "            # Calculate c using simulated x series\n",
    "            dx = xseries.diff().dropna()\n",
    "            sigma1 = dx.iloc[:,0].std()\n",
    "            sigma2 = dx.iloc[:,1].std()\n",
    "            corr =dx.corr().iloc[0,1]\n",
    "            \n",
    "            # Update parameters\n",
    "            self.model.update_c([sigma1,sigma2,corr])\n",
    "            p = p - np.linalg.inv(Hess).dot(Jac)*SSE\n",
    "            \n",
    "        return p, [self.model.sigma1,self.model.sigma2,self.model.rou], residuals       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = 0.01\n",
    "x2 = 0.02\n",
    "mu1 = 0.01\n",
    "mu2 = 0.008\n",
    "k1 = 0.08\n",
    "k2 = 0.12\n",
    "sigma1 = 0.02\n",
    "sigma2 = 0.02\n",
    "rou = 0.5\n",
    "model = Model(x1,x2,mu1,mu2,k1,k2,sigma1,sigma2,rou)\n",
    "term = [xx/4. for xx in range(1,21)]\n",
    "pfitter = pFitter(model,SampleA,term)\n",
    "fitresult = pfitter.fit(np.array([0.01,0.008,0.08,0.12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters p:  [0.01434384 0.01092208 0.07919113 0.11847654]\n",
      "Optimal parameters c:  [0.008537503457144009, 0.008668464150088241, -0.9988814238967613]\n"
     ]
    }
   ],
   "source": [
    "print('Optimal parameters p: ', fitresult[0])\n",
    "print('Optimal parameters c: ', fitresult[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate half life for a given series\n",
    "def half_life(data_srs):\n",
    "    # data_set is pandas Series\n",
    "    # Assume data_set follows an O-U process: dX = lambda*(X_bar-X)dt+sigma*dW\n",
    "    data_srs_demean = data_srs - data_srs.mean()\n",
    "    df_lag = data_srs_demean.shift(1).dropna()\n",
    "    df = data_srs_demean.drop(data_srs.index[0]).dropna()\n",
    "    lambdaa = -np.log(np.dot(df,df_lag)/np.dot(df,df)) # estimate lambda in O-U process\n",
    "    hl = np.log(2)/lambdaa\n",
    "    return hl # Here hl is in scale of days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ADF P Value  Half Life  Volitality  Norm Test P Value\n",
      "ED1      0.979475  33.769997    0.177851                0.0\n",
      "ED2      0.965145  37.755365    0.149216                0.0\n",
      "ED3      0.828680  40.529724    0.117496                0.0\n",
      "ED4      0.499365  30.421056    0.086066                0.0\n",
      "ED5      0.649988  38.816911    0.069492                0.0\n",
      "ED6      0.860959  28.182600    0.090343                0.0\n",
      "ED7      0.869071  41.285425    0.123780                0.0\n",
      "ED8      0.930435  31.572359    0.147726                0.0\n",
      "ED9      0.919446  31.613033    0.160656                0.0\n",
      "ED10     0.911592  29.645691    0.162587                0.0\n",
      "ED11     0.869613  27.752027    0.152979                0.0\n",
      "ED12     0.848191  26.841753    0.132033                0.0\n",
      "ED13     0.747907  14.467384    0.103712                0.0\n",
      "ED14     0.538571  56.060850    0.070846                0.0\n",
      "ED15     0.377579  15.395334    0.043804                0.0\n",
      "ED16     0.568509   3.164632    0.051684                0.0\n",
      "ED17     0.912514  38.783650    0.080776                0.0\n",
      "ED18     0.928930  38.356926    0.122929                0.0\n",
      "ED19     0.893947  24.904525    0.167268                0.0\n",
      "ED20     0.881080   6.003617    0.214627                0.0\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller as adf\n",
    "from scipy.stats import kstest\n",
    "\n",
    "# property list\n",
    "proplist = []\n",
    "\n",
    "# Residuals of fitting\n",
    "residuals = fitresult[2]\n",
    "\n",
    "# analyze properties for residuals\n",
    "for col in residuals.columns:\n",
    "    series = residuals[col]\n",
    "    \n",
    "    # Stationary property\n",
    "    adftest = adf(series,autolag='t-stat') \n",
    "    \n",
    "    # Half life\n",
    "    hl = half_life(series)\n",
    "    \n",
    "    # volitality\n",
    "    vol = series.std()\n",
    "    \n",
    "    # if residuals are normal distributed\n",
    "    isnorm = kstest(series,'norm')\n",
    "    \n",
    "    # append properties\n",
    "    proplist.append([adftest[1],hl,vol,isnorm[1]])\n",
    "\n",
    "properties = ['ADF P Value','Half Life','Volitality','Norm Test P Value']    \n",
    "propTest = pd.DataFrame(proplist,index = residuals.columns,columns = properties)\n",
    "print(propTest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some comments here:\n",
    "    This result shows that our 2-Factor Vasicek Model is not a good fit. The residuals are neither stationary nor normally \n",
    "distributed. Perhaps if our loop goes futher we can have a better fit. But my computer dont have that calculation ability so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal 1: \n",
      "            beta0     beta1  half_life\n",
      "(2y,3y) -0.094720  0.987473  54.982760\n",
      "(3y,4y) -0.057513  0.986417  50.683737\n",
      "(4y,5y) -0.013771  0.799965   3.105675\n",
      "(2y,4y) -0.135541  0.988137  58.084089\n",
      "(3y,5y) -0.086914  0.937223  10.691093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xj537\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal 2: \n",
      "            beta0     beta1  half_life    lambda\n",
      "(2y,3y) -0.005175  0.870547   4.999872  0.954802\n",
      "(3y,4y) -0.004915  0.870553   5.000112  0.951541\n",
      "(4y,5y)  0.167007  0.870547   4.999852  1.004874\n",
      "(2y,4y) -0.007958  0.870557   5.000249  0.953184\n",
      "(3y,5y) -0.048562  0.870548   4.999893  0.991520\n",
      "             CORR      RMSE\n",
      "signal1  0.706694  1.161632\n",
      "signal2  0.684891  0.551710\n",
      "signal3  0.602909  0.966183\n",
      "Optimal W:  [0.23731254]\n",
      "Q1:\n",
      "             CORR      RMSE\n",
      "signal1  0.215136  1.173165\n",
      "signal2  0.345577  0.595858\n",
      "signal3  0.157800  0.778967\n",
      "Combined Metric:  3.4253531637645818\n",
      "\n",
      "\n",
      "Q2:\n",
      "             CORR      RMSE\n",
      "signal1  0.111295  1.153562\n",
      "signal2  0.514837  0.563672\n",
      "signal3  0.078910  0.724750\n",
      "Combined Metric:  3.874806343568943\n",
      "\n",
      "\n",
      "Q3:\n",
      "             CORR      RMSE\n",
      "signal1  0.213459  1.130475\n",
      "signal2 -0.066878  0.680515\n",
      "signal3 -0.261903  0.688266\n",
      "Combined Metric:  14.468693615571539\n",
      "\n",
      "\n",
      "Q4:\n",
      "             CORR      RMSE\n",
      "signal1  0.534266  1.116553\n",
      "signal2  0.332559  0.777767\n",
      "signal3  0.487930  0.680297\n",
      "Combined Metric:  3.084983590295405\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Repeat Problem 1\n",
    "\n",
    "# Construct Signal 1\n",
    "# Parameters list\n",
    "paralist1 = []\n",
    "\n",
    "for i in range(len(wlist)):\n",
    "    \n",
    "    # Signal 1 cointegrated vector\n",
    "    citg_vec = residuals[Pairslist[i]].dot(wlist[i])\n",
    "    \n",
    "    # AR(1) Model fit\n",
    "    model = ARMA(citg_vec,(1,0)).fit(ic = 'aic',trend = 'c')\n",
    "    params = model.params.values\n",
    "    \n",
    "    # Calculate half-life\n",
    "    half_life = -np.log(2)/np.log(params[1])\n",
    "    \n",
    "    # Append parameters\n",
    "    paralist1.append(np.append(params,half_life))\n",
    "\n",
    "# Print out AR(1) fitting results and halflife\n",
    "print('Signal 1: ')\n",
    "pp = ['(2y,3y)','(3y,4y)','(4y,5y)','(2y,4y)','(3y,5y)']\n",
    "print(pd.DataFrame(paralist1,index=pp,columns=['beta0','beta1','half_life']))\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "# Construct Signal 2\n",
    "# Parameters list\n",
    "paralist2 = []\n",
    "\n",
    "for i in range(len(wlist)):\n",
    "    \n",
    "    # Signal 1 cointegrated vector\n",
    "    citg_vec = (SampleA[Pairslist[i]].values).dot(wlist[i])\n",
    "    \n",
    "    # Find lambda which assures halflife of signal2 is 5\n",
    "    minimizer = minimize(lambdaerror,x0=0.94,method='Nelder-Mead')\n",
    "    lambda_ =  minimizer['x']\n",
    "    \n",
    "    # Signal 2 cointegrated vector = Signal1 - EWMA \n",
    "    citg_vec = citg_vec - EWMA(citg_vec,lambda_)\n",
    "    \n",
    "    # AR(1) Model fit\n",
    "    model = ARMA(citg_vec,(1,0)).fit(ic = 'aic',trend = 'c')\n",
    "    params = model.params\n",
    "    \n",
    "    # Calculate halflife which should be 5\n",
    "    half_life = -np.log(2)/np.log(params[1])\n",
    "     \n",
    "    # Append parameters\n",
    "    paralist2.append(np.append(np.append(params,half_life),lambda_))\n",
    "\n",
    "# Print out AR(1) fitting results, lambda and halflife\n",
    "print('Signal 2: ')\n",
    "pp = ['(2y,3y)','(3y,4y)','(4y,5y)','(2y,4y)','(3y,5y)']\n",
    "print(pd.DataFrame(paralist2,index=pp,columns=['beta0','beta1','half_life','lambda']))    \n",
    "\n",
    "print(QualityAnalysis(0.5, SampleB))\n",
    "\n",
    "minimizer = minimize(toOptimizew,0.6,args=(SampleB),bounds=[(0,1)])\n",
    "Optimalw = minimizer['x']\n",
    "print('Optimal W: ', Optimalw)\n",
    "\n",
    "# Quality analysis on test sample\n",
    "print('Q1:')\n",
    "print(QualityAnalysis(Optimalw, SampleC1))\n",
    "print('Combined Metric: ', toOptimizew(Optimalw, SampleC1))\n",
    "print('\\n')\n",
    "\n",
    "print('Q2:')\n",
    "print(QualityAnalysis(Optimalw, SampleC2))\n",
    "print('Combined Metric: ', toOptimizew(Optimalw, SampleC2))\n",
    "print('\\n')\n",
    "\n",
    "print('Q3:')\n",
    "print(QualityAnalysis(Optimalw, SampleC3))\n",
    "print('Combined Metric: ', toOptimizew(Optimalw, SampleC3))\n",
    "print('\\n')\n",
    "\n",
    "print('Q4:')\n",
    "print(QualityAnalysis(Optimalw, SampleC4))\n",
    "print('Combined Metric: ', toOptimizew(Optimalw, SampleC4))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
